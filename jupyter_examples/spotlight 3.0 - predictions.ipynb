{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.cluster import KMeans\n",
    "from spotlight.cross_validation import random_train_test_split, user_based_train_test_split\n",
    "from spotlight.evaluation import precision_recall_score, sequence_mrr_score\n",
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "from spotlight.interactions import Interactions\n",
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "from spotlight.torch_utils import set_seed\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {'batch_size': 352, \n",
    "               'embedding_dim': 128, \n",
    "               'l2': 5.310207879958108e-07, \n",
    "               'learning_rate': 0.0025011952345768613, \n",
    "               'loss': 'adaptive_hinge', \n",
    "               'n_iter': 5, \n",
    "               'representation': 'lstm'}\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "FILE_PATH = './km_node_interactions_phase3_v2.csv'\n",
    "EXCLUDE_PATH = './exclude_ddi.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe():\n",
    "    \n",
    "    df = pd.read_csv(FILE_PATH)\n",
    "    if 'time_of_day' in df.columns:\n",
    "        df = df.drop(columns=['time_of_day', 'time_of_year', 'is_content_block'])\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df = df.drop(columns=['Unnamed: 0', 'js_key'])\n",
    "        \n",
    "    sub_col = 'subscriber_id'\n",
    "    block_col = 'ddi_id'\n",
    "    time_col = 'entry_at'\n",
    "    \n",
    "    # preprocess dataframe\n",
    "    df[time_col] = pd.to_datetime(df[time_col])\n",
    "    df.sort_values(by=time_col, inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop(columns='index', inplace=True)\n",
    "    \n",
    "    # create idx mapping compatible with spotlight, map users and items\n",
    "    user_mapping = {k:v for v, k in enumerate(df[sub_col].unique())}\n",
    "    item_mapping = {k:v for v, k in enumerate(df[block_col].unique(), 1)}\n",
    "    df['user_id'] = df[sub_col].map(user_mapping)\n",
    "    df['item_id'] = df[block_col].map(item_mapping)\n",
    "    \n",
    "    return (df, user_mapping, item_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df, hyperparams):\n",
    "    # Fix random_state\n",
    "    seed = 42\n",
    "    set_seed(seed)\n",
    "    random_state = np.random.RandomState(seed)\n",
    "\n",
    "    max_sequence_length = 15\n",
    "    min_sequence_length = 2\n",
    "    step_size = 1\n",
    "    \n",
    "    # create dataset using interactions dataframe and timestamps\n",
    "    dataset = Interactions(user_ids=np.array(df['user_id'], dtype='int32'), \n",
    "                           item_ids=np.array(df['item_id'], dtype='int32'), \n",
    "                           timestamps=df['entry_at'])\n",
    "    \n",
    "    # create training and test sets using a 80/20 split\n",
    "    train, test = user_based_train_test_split(\n",
    "        dataset,\n",
    "        test_percentage=0.2,\n",
    "        random_state=random_state)\n",
    "    # convert to sequences\n",
    "    train = train.to_sequence(\n",
    "        max_sequence_length=max_sequence_length,\n",
    "        min_sequence_length=min_sequence_length,\n",
    "        step_size=step_size)\n",
    "    test = test.to_sequence(\n",
    "        max_sequence_length=max_sequence_length,\n",
    "        min_sequence_length=min_sequence_length,\n",
    "        step_size=step_size)\n",
    "\n",
    "    print('data: {}'.format(train))\n",
    "    \n",
    "    # initialize and train model\n",
    "    model = ImplicitSequenceModel(\n",
    "            **hyperparams,\n",
    "            use_cuda=CUDA,\n",
    "            random_state=random_state)\n",
    "    model.fit(train, verbose=True)\n",
    "    \n",
    "    # compute mrr score on test set\n",
    "    test_mrr = sequence_mrr_score(model, test).mean()\n",
    "    print('MRR score on test set: {}'.format(test_mrr))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_predictions(df, model):\n",
    "    num_users = len(df['user_id'].unique())\n",
    "    num_items = len(df['item_id'].unique())\n",
    "    predictions = np.zeros(shape=(num_users, num_items+1))\n",
    "    \n",
    "    dataset = Interactions(user_ids=np.array(df['user_id'], dtype='int32'), \n",
    "                           item_ids=np.array(df['item_id'], dtype='int32'), \n",
    "                           timestamps=df['entry_at'])\n",
    "    sequences = dataset.to_sequence(max_sequence_length=15)\n",
    "    \n",
    "    user_id = 0\n",
    "\n",
    "    for user, sequence in zip(sequences.user_ids, sequences.sequences):\n",
    "        if user == user_id:\n",
    "            predictions[user] = model.predict(sequence)\n",
    "            user_id += 1\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_predictions(ind_predictions, user_mapping, item_mapping):\n",
    "    kmeans_params = {'n_clusters':50,\n",
    "                 'n_init':5,\n",
    "                 'max_iter':50,\n",
    "                 'precompute_distances':True,\n",
    "                 'random_state':42,\n",
    "                 'verbose':1}\n",
    "    \n",
    "    kmeans = KMeans(**kmeans_params)\n",
    "    print(\"Fitting {} K-Means models...\".format(kmeans_params['n_init']))\n",
    "    clusters = kmeans.fit_predict(ind_predictions)\n",
    "    \n",
    "    clusters_to_users = defaultdict(list)\n",
    "\n",
    "    for user, cluster in enumerate(clusters):\n",
    "        clusters_to_users[cluster].append(user)\n",
    "        \n",
    "    clusters_to_recommendations = {}\n",
    "    n = 20\n",
    "\n",
    "    for cluster in clusters_to_users.keys():\n",
    "        cluster_predictions = ind_predictions[clusters_to_users[cluster], :]\n",
    "        avg_predictions = np.median(cluster_predictions, axis=0)\n",
    "        ranks = len(avg_predictions) + 1 - rankdata(avg_predictions).astype(int)\n",
    "        recommendations = [np.where(ranks == k)[0][0] for k in range(1, n+1)]\n",
    "        clusters_to_recommendations[cluster] = recommendations\n",
    "        \n",
    "    df_removed = pd.read_csv(EXCLUDE_PATH)\n",
    "    removed_ddi_blocks = list(df_removed['0'])\n",
    "    removed_ids = [item_mapping[x] for x in removed_ddi_blocks]\n",
    "    \n",
    "    k = 5\n",
    "    for cluster, recommendations in clusters_to_recommendations.items():\n",
    "        topk = []\n",
    "        i = 0\n",
    "        while len(topk) < k:\n",
    "            if recommendations[i] not in removed_ids:\n",
    "                topk.append(recommendations[i])\n",
    "            i += 1\n",
    "        clusters_to_recommendations[cluster] = topk\n",
    "        \n",
    "    return (clusters, clusters_to_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, user_mapping, item_mapping = create_dataframe()\n",
    "model = train_model(df=df, hyperparams=hyperparams)\n",
    "individual_scores = individual_predictions(df=df, model=model)\n",
    "clusters, clusters_to_recommendations = group_predictions(ind_predictions=individual_scores, \n",
    "                                                          user_mapping=user_mapping,\n",
    "                                                          item_mapping=item_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_userid = {v: k for k, v in user_mapping.items()}\n",
    "idx_to_block = {v: k for k, v in item_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create user to cluster dataframe\n",
    "df_clusters = pd.DataFrame(clusters)\n",
    "df_clusters.reset_index(inplace=True)\n",
    "df_clusters.rename({'index':'User ID', 0:'Group ID'}, axis=1, inplace=True)\n",
    "df_clusters['User ID'] = df_clusters['User ID'].map(idx_to_userid)\n",
    "df_clusters.to_csv('./user_groups_20190813.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create cluster to recommendations dataframe\n",
    "df_recommendations = pd.DataFrame.from_dict(clusters_to_recommendations, orient='index')\n",
    "df_recommendations.reset_index(inplace=True)\n",
    "df_recommendations.rename({'index':'Group ID'}, axis=1, inplace=True)\n",
    "df_recommendations.sort_values(by='Group ID', inplace=True)\n",
    "for col in range(5):\n",
    "    df_recommendations[col] = df_recommendations[col].map(idx_to_block)\n",
    "df_recommendations.rename({0:'First', 1:'Second', 2:'Third', 3:'Fourth', 4:'Fifth'}, axis=1, inplace=True)\n",
    "df_recommendations.to_csv('./group_recommendations_20190813.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cubica",
   "language": "python",
   "name": "cubica"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
