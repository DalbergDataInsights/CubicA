{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import hyperopt\n",
    "from hyperopt import tpe, Trials, hp, fmin, STATUS_OK, STATUS_FAIL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from spotlight.cross_validation import random_train_test_split, user_based_train_test_split\n",
    "from spotlight.evaluation import precision_recall_score, sequence_mrr_score\n",
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "from spotlight.interactions import Interactions\n",
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "from spotlight.torch_utils import set_seed\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "FILE_PATH = './km_node_interactions_phase3_v2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_space():\n",
    "    \"\"\"Define hyperopt hyperparameter space\"\"\"\n",
    "\n",
    "    space = {\n",
    "        'batch_size': hp.quniform('batch_size', 128, 384, 16),\n",
    "        'learn_rate': hp.loguniform('learn_rate', -6, -3),\n",
    "        'l2': hp.loguniform('l2', -25, -9),\n",
    "        'n_iter': hp.quniform('n_iter', 5, 10, 1),\n",
    "        'loss': hp.choice('loss', ['adaptive_hinge', 'pointwise', 'bpr', 'hinge',]),\n",
    "        'embedding_dim': hp.quniform('embedding_dim', 16, 128, 8),\n",
    "        'representation': hp.choice('representation', ['cnn', 'lstm',])\n",
    "    }\n",
    "    \n",
    "    return space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_objective(train, valid, test, random_state=None):\n",
    "\n",
    "    def objective(space):\n",
    "        \"\"\"Objective function for Spotlight ImplicitFactorizationModel\"\"\"\n",
    "\n",
    "        batch_size = int(space['batch_size'])\n",
    "        embedding_dim = int(space['embedding_dim'])\n",
    "        l2 = space['l2']\n",
    "        learn_rate = space['learn_rate']\n",
    "        loss = space['loss']\n",
    "        n_iter = int(space['n_iter'])\n",
    "        representation = space['representation']\n",
    "        \n",
    "        model = ImplicitSequenceModel(\n",
    "            loss=loss,\n",
    "            embedding_dim=embedding_dim,\n",
    "            batch_size=batch_size,\n",
    "            representation=representation,\n",
    "            learning_rate=learn_rate,\n",
    "            n_iter=n_iter,\n",
    "            l2=l2,\n",
    "            use_cuda=CUDA,\n",
    "            random_state=random_state)\n",
    "        \n",
    "        start = time.clock()\n",
    "        try:\n",
    "            model.fit(train, verbose=True)\n",
    "        except ValueError:\n",
    "            elapsed = time.clock() - start\n",
    "            return {'loss': 0.0,\n",
    "                    'status': STATUS_FAIL,\n",
    "                    'validation_mrr': 0.0,\n",
    "                    'test_mrr': 0.0,\n",
    "                    'elapsed': elapsed,\n",
    "                    'hyper': space}\n",
    "        elapsed = time.clock() - start\n",
    "        print(model)\n",
    "\n",
    "        validation_mrr = sequence_mrr_score(model, valid).mean()\n",
    "        test_mrr = sequence_mrr_score(model, test).mean()\n",
    "\n",
    "        print('MRR {} {}'.format(validation_mrr, test_mrr))\n",
    "\n",
    "        if np.isnan(validation_mrr):\n",
    "            status = STATUS_FAIL\n",
    "        else:\n",
    "            status = STATUS_OK\n",
    "\n",
    "        return {'loss': -validation_mrr,\n",
    "                'status': status,\n",
    "                'validation_mrr': validation_mrr,\n",
    "                'test_mrr': test_mrr,\n",
    "                'elapsed': elapsed,\n",
    "                'hyper': space}\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(objective, space, trials_fname=None, max_evals=5):\n",
    "\n",
    "    if trials_fname is not None and os.path.exists(trials_fname):\n",
    "        with open(trials_fname, 'rb') as trials_file:\n",
    "            trials = pickle.load(trials_file)\n",
    "    else:\n",
    "        trials = Trials()\n",
    "\n",
    "    fmin(objective,\n",
    "         space=space,\n",
    "         algo=tpe.suggest,\n",
    "         trials=trials,\n",
    "         max_evals=max_evals)\n",
    "\n",
    "    if trials_fname is not None:\n",
    "        temporary = '{}.temp'.format(trials_fname)\n",
    "        with open(temporary, 'wb') as trials_file:\n",
    "            pickle.dump(trials, trials_file)\n",
    "        shutil.move(temporary, trials_fname)\n",
    "\n",
    "    return trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_trials(trials):\n",
    "    results = trials.trials\n",
    "\n",
    "    results = sorted(results, key=lambda x: -x['result']['validation_mrr'])\n",
    "\n",
    "    if results:\n",
    "        print('Best: {}'.format(results[0]['result']))\n",
    "\n",
    "    results = sorted(results, key=lambda x: -x['result']['test_mrr'])\n",
    "\n",
    "    if results:\n",
    "        print('Best test MRR: {}'.format(results[0]['result']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(max_evals):\n",
    "    status = 'available' if CUDA else 'not available'\n",
    "    print(\"CUDA is {}!\".format(status))\n",
    "\n",
    "    # Fix random_state\n",
    "    seed = 42\n",
    "    set_seed(seed)\n",
    "    random_state = np.random.RandomState(seed)\n",
    "\n",
    "    max_sequence_length = 15\n",
    "    min_sequence_length = 2\n",
    "    step_size = 1\n",
    "\n",
    "    df = pd.read_csv(FILE_PATH)\n",
    "    if 'time_of_day' in df.columns:\n",
    "        df = df.drop(columns=['time_of_day', 'time_of_year', 'is_content_block'])\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df = df.drop(columns=['Unnamed: 0', 'js_key'])\n",
    "        \n",
    "    sub_col = 'subscriber_id'\n",
    "    block_col = 'ddi_id'\n",
    "    time_col = 'entry_at'\n",
    "    \n",
    "    # preprocess dataframe\n",
    "    df[time_col] = pd.to_datetime(df[time_col])\n",
    "    df.sort_values(by=time_col, inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop(columns='index', inplace=True)\n",
    "    \n",
    "    # create idx mapping compatible with spotlight, map users and items\n",
    "    sub_mapping = {k:v for v, k in enumerate(df[sub_col].unique())}\n",
    "    block_mapping = {k:v for v, k in enumerate(df[block_col].unique(), 1)}\n",
    "    df['user_id'] = df[sub_col].map(sub_mapping)\n",
    "    df['item_id'] = df[block_col].map(block_mapping)\n",
    "    \n",
    "    # create dataset using interactions and timestamps\n",
    "    dataset = Interactions(user_ids=np.array(df['user_id'], dtype='int32'), \n",
    "                           item_ids=np.array(df['item_id'], dtype='int32'), \n",
    "                           timestamps=df[time_col])\n",
    "    \n",
    "    # create training, validation and test sets using a 80/10/10 split\n",
    "    train, rest = user_based_train_test_split(\n",
    "        dataset,\n",
    "        test_percentage=0.2,\n",
    "        random_state=random_state)\n",
    "    test, valid = user_based_train_test_split(\n",
    "        rest,\n",
    "        test_percentage=0.5,\n",
    "        random_state=random_state)\n",
    "    # convert to sequences\n",
    "    train = train.to_sequence(\n",
    "        max_sequence_length=max_sequence_length,\n",
    "        min_sequence_length=min_sequence_length,\n",
    "        step_size=step_size)\n",
    "    test = test.to_sequence(\n",
    "        max_sequence_length=max_sequence_length,\n",
    "        min_sequence_length=min_sequence_length,\n",
    "        step_size=step_size)\n",
    "    valid = valid.to_sequence(\n",
    "        max_sequence_length=max_sequence_length,\n",
    "        min_sequence_length=min_sequence_length,\n",
    "        step_size=step_size)\n",
    "\n",
    "    print('data: {}'.format(train))\n",
    "\n",
    "    dtime = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    fname = './experiment_{}.pickle'.format(dtime)\n",
    "    objective = get_objective(train, valid, test, random_state)\n",
    "    space = hyperparameter_space()\n",
    "\n",
    "    trials = optimize(objective,\n",
    "                      space,\n",
    "                      trials_fname=fname,\n",
    "                      max_evals=max_evals)\n",
    "\n",
    "    summarize_trials(trials)\n",
    "    \n",
    "    return trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_final = main(max_evals=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cubica",
   "language": "python",
   "name": "cubica"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
